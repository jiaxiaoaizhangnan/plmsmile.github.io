<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
    

    

    



    <meta charset="utf-8">
    
    
    
    
    <title>PLM&#39;s Notes | 好好学习，天天笔记</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="">
    <meta name="description" content="NLP, DL, MRC.">
<meta property="og:type" content="website">
<meta property="og:title" content="PLM&#39;s Notes">
<meta property="og:url" content="http://plmsmile.github.io/page/4/index.html">
<meta property="og:site_name" content="PLM&#39;s Notes">
<meta property="og:description" content="NLP, DL, MRC.">
<meta property="og:locale" content="zh-CN">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="PLM&#39;s Notes">
<meta name="twitter:description" content="NLP, DL, MRC.">
    
        <link rel="alternate" type="application/atom+xml" title="PLM&#39;s Notes" href="/atom.xml">
    
    <link rel="shortcut icon" href="/img/favicon.png">
    <link rel="stylesheet" href="/css/style.css?v=1.7.2">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu">
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">PLM</h5>
          <a href="mailto:plmsmile@126.com" title="plmsmile@126.com" class="mail">plmsmile@126.com</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/">
                <i class="icon icon-lg icon-home"></i>
                主页
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives">
                <i class="icon icon-lg icon-archives"></i>
                归档
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags">
                <i class="icon icon-lg icon-tags"></i>
                标签
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/categories">
                <i class="icon icon-lg icon-th-list"></i>
                类别
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/about">
                <i class="icon icon-lg icon-user"></i>
                关于我
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/plmsmile" target="_blank">
                <i class="icon icon-lg icon-github"></i>
                Github
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">PLM&#39;s Notes</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="输入感兴趣的关键字">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header index-header">

    <div class="container fade-scale">
        <h1 class="title">PLM&#39;s Notes</h1>
        <h5 class="subtitle">
            
                好好学习，天天笔记
            
        </h5>
    </div>

    


</header>

<div class="container body-wrap">

    <ul class="post-list">
    
        <li class="post-list-item fade">
            <article id="post-谷歌翻译论文笔记" class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2017-10-17 13:25:38" datetime="2017-10-17T05:25:38.000Z" itemprop="datePublished">2017-10-17</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/论文笔记/">论文笔记</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2017/10/17/谷歌翻译论文笔记/">谷歌翻译论文笔记</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        
谷歌神经机器翻译系统


简介神经机器翻译是自动翻译的端到端的学习方法，克服了传统的基于词典翻译的许多缺点。但仍然有以下的缺点

训练和翻译都太慢了，花费代价很大
缺乏鲁棒性，特别是输入句子包含生僻词汇
精确度和速度也不行

传统NMT缺点神经机器翻译(NMT)是自动翻译的端到端的学习方法。NMT一般由两个RNN组成，分别处理输入句子和生成目标句子。一般会使用注意力机制，会有效地去处理长句...
    

        <a href="/2017/10/17/谷歌翻译论文笔记/" class="post-more waves-effect waves-button">
            点击阅读全文
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/神经机器翻译/">神经机器翻译</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/论文笔记/">论文笔记</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-tips" class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2017-10-16 22:47:46" datetime="2017-10-16T14:47:46.000Z" itemprop="datePublished">2017-10-16</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/心得体会/">心得体会</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2017/10/16/tips/">那些年折磨过的问题</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        搭建博客搭建博客12345678910111213141516171819202122232425mkdir PLMBlogscd PLMBlogs# install hexonpm install hexo-cli -g# inithexo init npm installhexo server# install pluginsnpm install hexo-deployer-git -...
    

        <a href="/2017/10/16/tips/" class="post-more waves-effect waves-button">
            点击阅读全文
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/hexo/">hexo</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/latex/">latex</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/pyplot/">pyplot</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/中文/">中文</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/心得/">心得</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-Attention-based-NMT" class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2017-10-12 16:12:39" datetime="2017-10-12T08:12:39.000Z" itemprop="datePublished">2017-10-12</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/自然语言处理/">自然语言处理</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2017/10/12/Attention-based-NMT/">注意力机制和PyTorch实现机器翻译</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        
Effective Approaches to Attention-based Neural Machine Translation
前面阐述注意力理论知识，后面简单描述PyTorch利用注意力实现机器翻译

简介
Attention介绍在翻译的时候，选择性的选择一些重要信息。详情看这篇文章 。
本着简单和有效的原则，本论文提出了两种注意力机制。
Global
每次翻译时，都选择关注所有的...
    

        <a href="/2017/10/12/Attention-based-NMT/" class="post-more waves-effect waves-button">
            点击阅读全文
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Attention/">Attention</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器翻译/">机器翻译</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/注意力/">注意力</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/深度学习/">深度学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/自然语言处理/">自然语言处理</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/论文笔记/">论文笔记</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-attention-model" class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2017-10-10 11:40:01" datetime="2017-10-10T03:40:01.000Z" itemprop="datePublished">2017-10-10</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/自然语言处理/">自然语言处理</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2017/10/10/attention-model/">图文介绍注意力机制</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        Encoder-Decoder基本介绍举个翻译的例子，原始句子$X = (x_1, x_2, \cdots, x_m)$ ，翻译成目标句子$Y = (y_1, y_2, \cdots, y_n)$ 。
现在采用Encoder-Decoder架构模型，如下图

Encoder会利用整个原始句子生成一个语义向量，Decoder再利用这个向量翻译成其它语言的句子。这样可以把握整个句子的意思、句法结...
    

        <a href="/2017/10/10/attention-model/" class="post-more waves-effect waves-button">
            点击阅读全文
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Attention-Model/">Attention Model</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Encoder-Decoder/">Encoder-Decoder</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器翻译/">机器翻译</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/注意力/">注意力</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/自然语言处理/">自然语言处理</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-pytorch-start" class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2017-10-05 13:30:54" datetime="2017-10-05T05:30:54.000Z" itemprop="datePublished">2017-10-05</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/PyTorch/">PyTorch</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2017/10/05/pytorch-start/">PyTorch快速上手</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        PyTorch介绍
PyTorchTorch 是一个使用Lua 语言的神经网络库，而PyTorch是Torch在Python的衍生。
PyTorch是一个基于python的科学计算包。本质上是Numpy的代替者，支持GPU、带有高级功能，可以用来搭建和训练深度神经网络；是一个深度学习框架，速度更快，弹性更好。
PyTorch和TensorflowTensorflow 类似一个嵌入Python...
    

        <a href="/2017/10/05/pytorch-start/" class="post-more waves-effect waves-button">
            点击阅读全文
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/PyTorch/">PyTorch</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/深度学习/">深度学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/神经网络/">神经网络</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-NMT" class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2017-10-02 10:03:31" datetime="2017-10-02T02:03:31.000Z" itemprop="datePublished">2017-10-02</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/自然语言处理/">自然语言处理</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2017/10/02/NMT/">神经网络机器翻译</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        
在机器翻译、语音识别、文本摘要等领域中，Sequence-to-sequence 模型都取得了了非常好的效果。神经机器翻译(Neural Machine Translation, NMT)  使用seq2seq模型取得了巨大的成功。

本文参考谷歌NMT教程。
Basic
背景知识传统翻译是以词为核心一词一词翻译的，这样会切断句子本身的意思，翻译出来也很死板，不像我们人类说的话。
Enco...
    

        <a href="/2017/10/02/NMT/" class="post-more waves-effect waves-button">
            点击阅读全文
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器翻译/">机器翻译</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/深度学习/">深度学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/自然语言处理/">自然语言处理</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-crf" class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2017-09-28 11:17:59" datetime="2017-09-28T03:17:59.000Z" itemprop="datePublished">2017-09-28</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/自然语言处理/">自然语言处理</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2017/09/28/crf/">条件随机场</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        
条件随机场(Conditional Random Field, CRF)是给定一组输入随机变量条件下另一组输出随机变量的条件概率分布模型。常常用于标注问题。隐马尔科夫模型和条件随机场是自然语言处理中最重要的算法。CRF最重要的就是根据观测序列，把标记序列给推测出来。

概率无向图模型概率无向图模型又称为马尔科夫随机场，是一个可以由无向图表示的联合概率分布。一些类似内容。
有一组随机变量$Y...
    

        <a href="/2017/09/28/crf/" class="post-more waves-effect waves-button">
            点击阅读全文
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/条件随机场/">条件随机场</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/自然语言处理/">自然语言处理</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-maxentmodel" class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2017-09-20 17:39:12" datetime="2017-09-20T09:39:12.000Z" itemprop="datePublished">2017-09-20</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/自然语言处理/">自然语言处理</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2017/09/20/maxentmodel/">最大熵模型</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        最大熵原理预备知识离散型变量$X$的概率分布是$\color{blue}{P(X)}$。它的熵$\color{blue}{H(X) \; or \; H(P)}$越大，代表越均匀、越混乱、越不确定。各种熵点这里$$\color{blue}{H(P)} =  \color{red} {- \sum_{x \in X}P(x) \log P(x)}$$熵满足下面不等式$$0 \le H(P) \...
    

        <a href="/2017/09/20/maxentmodel/" class="post-more waves-effect waves-button">
            点击阅读全文
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/IIS/">IIS</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/各种熵/">各种熵</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/最大熵模型/">最大熵模型</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/期望/">期望</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/自然语言处理/">自然语言处理</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-ml-ng-notes" class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2017-08-20 21:38:54" datetime="2017-08-20T13:38:54.000Z" itemprop="datePublished">2017-08-20</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/机器学习/">机器学习</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2017/08/20/ml-ng-notes/">机器学习笔记</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        线性回归有$m$个样本$(x^{(1)}, y^{(1)}), (x^{(2)}, y^{(2)}), \cdots, (x^{(m)}, y^{(m)})$，假设函数有2个参数$\theta_0, \theta_1$，形式如下：$$h_\theta(x) = \theta_0 + \theta_1x$$
代价函数代价函数$$\color{red} {J(\theta_0, \theta_1...
    

        <a href="/2017/08/20/ml-ng-notes/" class="post-more waves-effect waves-button">
            点击阅读全文
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/梯度下降/">梯度下降</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/逻辑回归/">逻辑回归</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-em" class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2017-08-13 18:37:48" datetime="2017-08-13T10:37:48.000Z" itemprop="datePublished">2017-08-13</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/机器学习/">机器学习</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2017/08/13/em/">最大期望算法</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        EM算法定义背景如果概率模型的变量都是观测变量，那么可以直接使用极大似然估计法或贝叶斯估计法去估计模型参数。
如果模型既有观测变量又有隐变量，就不能简单使用上述方法。
EM算法，期望极大算法，就是含有隐变量的概率模型参数的极大似然估计法或极大后验概率估计法，是一种迭代算法。每次迭代分为如下两步

E步：求期望(expectation)
M步：求极大(maximization)

三硬币模型有...
    

        <a href="/2017/08/13/em/" class="post-more waves-effect waves-button">
            点击阅读全文
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Jesen不等式/">Jesen不等式</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/最大期望算法/">最大期望算法</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/机器学习/">机器学习</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-pgm-01" class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2017-08-04 11:06:41" datetime="2017-08-04T03:06:41.000Z" itemprop="datePublished">2017-08-04</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/自然语言处理/">自然语言处理</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2017/08/04/pgm-01/">马尔可夫模型</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        概述产生式和判别式
判别方法 由数据直接去学习决策函数$Y=f(X)$ 或者$P(Y \mid X)$作为预测模型 ，即判别模型


生成方法 先求出联合概率密度$P(X, Y)$，然后求出条件概率密度$P(Y \mid X)$。即生成模型$P(Y \mid X) = \frac {P(X, Y)} {P(X)}$





判别式
生成式




原理
直接求$Y=f(X)$ 或$P(Y ...
    

        <a href="/2017/08/04/pgm-01/" class="post-more waves-effect waves-button">
            点击阅读全文
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/前向算法/">前向算法</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/后向算法，BW算法/">后向算法，BW算法</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/概率图模型/">概率图模型</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/维特比算法/">维特比算法</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/自然语言处理/">自然语言处理</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/隐马尔科夫模型/">隐马尔科夫模型</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/马尔可夫链/">马尔可夫链</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-nlp-notes" class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2017-07-31 08:57:52" datetime="2017-07-31T00:57:52.000Z" itemprop="datePublished">2017-07-31</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/自然语言处理/">自然语言处理</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2017/07/31/nlp-notes/">语言模型和平滑方法</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        语言模型二元语法$ $
对于一个句子$s=w_1 \cdots w_n$，近似认为一个词的概率只依赖于它前面的1个词。即一个状态只跟上一个状态有关，也称为一阶马尔科夫链。
$$\color{blue}{p(s)}=p(w_1)p(w_2|w_1)p(w_3|w_2) \cdots p(w_n|w_{l-1})= \color {red} {\prod_{i=1}^l {p(w_i|w_{i-...
    

        <a href="/2017/07/31/nlp-notes/" class="post-more waves-effect waves-button">
            点击阅读全文
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/各种熵/">各种熵</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/数据平滑/">数据平滑</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/自然语言处理/">自然语言处理</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/语言模型/">语言模型</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-aim2offer" class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2017-07-29 11:42:07" datetime="2017-07-29T03:42:07.000Z" itemprop="datePublished">2017-07-29</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/leetcode/">leetcode</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2017/07/29/aim2offer/">剑指Offer算法题</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        数组中重复的数字-03题目1找到数组中重复的数字

一个数组存放n个数字，所有数字在[0, n-1]范围内。某些数字是随机重复的。请找出任意一个重复的数字。例如[2,3,1,0,2,5,3]，输出2或3

思路1
对数组进行排序，然后可以找出重复的数字。但是排序的时间复杂度是O(nlogn)
思路2
使用哈希表，每次存放的时候检查是否在哈希表中，如果已经存在，那么就重复了。时间复杂度O(n)...
    

        <a href="/2017/07/29/aim2offer/" class="post-more waves-effect waves-button">
            点击阅读全文
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/leetcode/">leetcode</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/排序/">排序</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-cnn-mnist" class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2017-07-18 19:23:56" datetime="2017-07-18T11:23:56.000Z" itemprop="datePublished">2017-07-18</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/深度学习/">深度学习</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2017/07/18/cnn-mnist/">简单的卷积神经网络</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        卷积神经网络概要卷积神经网络(Convolutional Neural Network, CNN)是人工神经网络中的一种，是一种特殊的对图像识别的方式，属于非常有效的带有前向反馈的网络。也用于音频信号、文本数据、人脸识别等等。$ $
CNN不需要把特征提取和分类训练两个过程分开，在训练的时候就提取了最有效的特征，降低了对图形数据预处理的要求。

卷积神经网络的核心思想是将输入信息切分成一个个...
    

        <a href="/2017/07/18/cnn-mnist/" class="post-more waves-effect waves-button">
            点击阅读全文
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/">tensorflow</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/卷积/">卷积</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/深度学习/">深度学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/神经网络/">神经网络</a></li></ul>

    </div>
    
</article>

        </li>
    
        <li class="post-list-item fade">
            <article id="post-word2vec" class="article-card article-type-post" itemprop="blogPost">

    <div class="post-meta">
        <time class="post-time" title="2017-07-14 20:17:50" datetime="2017-07-14T12:17:50.000Z" itemprop="datePublished">2017-07-14</time>

        
	<ul class="article-category-list"><li class="article-category-list-item"><a class="article-category-list-link" href="/categories/深度学习/">深度学习</a></li></ul>



    </div>

    


  
    <h3 class="post-title" itemprop="name">
      <a class="post-title-link" href="/2017/07/14/word2vec/">利用tensorflow实现简版word2vec</a>
    </h3>
  




    <div class="post-content" id="post-content" itemprop="postContent">

    
        相关知识传统方法One-Hot Encoder 是一个词对应一个向量，向量中只有一个是1，其余是0，离散表达。$ $
Bag of Words 标识当前单词那一位不是1，而是变成了当前单词的出现次数。
存在的问题 需要大量的维数去表示，编码随机的，没有任何关联的信息。
向量空间模型Vector Space Models可以把字词转化为连续值，并将意思相近的词被映射到向量空间相近的位置。
VS...
    

        <a href="/2017/07/14/word2vec/" class="post-more waves-effect waves-button">
            点击阅读全文
        </a>
    </div>
    
    <div class="post-footer">
        
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/word2vec/">word2vec</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/深度学习/">深度学习</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/自然语言处理/">自然语言处理</a></li></ul>

    </div>
    
</article>

        </li>
    
    </ul>

    
<nav id="page-nav">
    <div class="inner">
    <a class="extend prev" rel="prev" href="/page/3/">上一页</a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><a class="page-number" href="/page/3/">3</a><span class="page-number current">4</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/5/">下一页</a>
    </div>
</nav>


</div>

        <footer class="footer">
    <div class="bottom">
        
<p>
    <span id="busuanzi_container_site_uv" style="display:none">
        总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style="display:none">
        总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            <span>
            PLM's Notes &nbsp; &copy; &nbsp
            </span>
            2016 - 2018
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://plmsmile.github.io/page/4/&title=PLM's Notes&pic=http://plmsmile.github.io/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://plmsmile.github.io/page/4/&title=PLM's Notes&source=NLP, DL, MRC." data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://plmsmile.github.io/page/4/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=PLM's Notes&url=http://plmsmile.github.io/page/4/&via=http://plmsmile.github.io" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://plmsmile.github.io/page/4/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAK4AAACuCAAAAACKZ2kyAAABzklEQVR42u3aQY7CMAwFUO5/aUaaFRLT8B0nmSK9rlCh9KULy/7p4xEfz9/j/fPVmdfzV9deXbXgwMXFbXOfw2P8m6tvxwvL//+PJeHi4h7k7ihe46uSooaLi3t/btKyjBuXvOTh4uJ+O7davHBxcb+Fm4w3nRglL4LLZjVcXNwGtxOYrvp8KN/FxcVt70rMlbb8qvJ9cXFxj3DzdqTarCRbrePz0ayGi4t7hLu2MI3vkj8OXFzc89z8hao81qxeWwhMcXFxj3A7GyFJ6ak2MdHwg4uLu42bjzHVdmTVf14+V1xc3G3cakiRgKoFK293cHFxz3DXRpn5v+WBS1R3cXFxl3LzWtEvT8s2WXFxcY9wy2tqh61zZ3Bxcc9w5xqXHeNTtM+Di4t7hDt3406ZqzZSCxIdXFzcIrcaW8zFo0n8Ud5kxcXF3cbtF7KkiZkrf+Ml4eLi7uPORZbV8SZ/BB8GJFxc3CPc6rhSjVmr2yrlWQ0XF3cbN79xstY8Bk1Gr3L1xcXFXcpNxo9qGaouNfo9Li7ujbn98WZyKMLFxb0Ztx98zL3egYuL+1/cVeFm3gwl27TRSxi4uLgbuJ3AdG5DpdroLMt3cXFxP3N/AMfnYulHT9PUAAAAAElFTkSuQmCC" alt="微信分享二维码">
</div>




    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: false };


</script>

<script src="/js/main.min.js?v=1.7.2"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="/js/search.min.js?v=1.7.2" async></script>



<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>




<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>





</body>
</html>
